{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw9rgAa9tZoz",
        "outputId": "f4cf22b5-e2da-4b76-de1b-4e1c776097fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import random\n",
        "from PIL import Image\n",
        "!pip install pydicom\n",
        "import pydicom\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "from nibabel.testing import data_path\n",
        "import nibabel as nib\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "SubCbaMutiPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f1136b-9d7c-46f9-d2b7-1088a8324115"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydicom\n",
            "  Downloading pydicom-2.3.1-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data = ['/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (101)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (102)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (103)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (104)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (105)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (106)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (107)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (108)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1000)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1001)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1002)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1003)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1004)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1006)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1007)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1008)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1009)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1010)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1059)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1060)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1061)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1062)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1063)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1064)/*',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Subject (1065)/*',]\n",
        "\n",
        "\n",
        "data = []\n",
        "for i in range(len(Data)):\n",
        "  for name in glob.glob(Data[i]):\n",
        "    image  = pydicom.dcmread(name)\n",
        "    image = image.pixel_array.astype(float)\n",
        "    new_image = cv2.resize(image, (128, 128))\n",
        "    data.append(new_image)"
      ],
      "metadata": {
        "id": "7u8VVJ2K_-qd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_cases = data\n",
        "len(positive_cases)\n",
        "\n",
        "positive_cases = np.array(positive_cases)/255\n",
        "\n",
        "print(positive_cases.shape)\n",
        "print(positive_cases.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMuVpvh-CipM",
        "outputId": "aa160cf6-e313-4441-a70a-af9a985bc8be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8537, 128, 128)\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_path = '/content/drive/MyDrive/Colab Notebooks/COVID_Project/Normal/*.jpg'\n",
        "normal_data = []\n",
        "for name in glob.glob(normal_path):\n",
        "  image  = cv2.imread(name, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "  new_image = cv2.resize(image, (128, 128))\n",
        "  normal_data.append(new_image)\n",
        "\n",
        "len(normal_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhKIeDlUJ4ji",
        "outputId": "2207ecec-bfa3-4272-ec64-78737c8f60c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3840"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_data = np.array(normal_data)/255\n",
        "print(normal_data.shape)\n",
        "print(normal_data.ndim)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5TiCqBoEL9T",
        "outputId": "9ee63ec7-e6ff-4f69-b7bd-3ef9a82c08b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3840, 128, 128)\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data  = [normal_data, positive_cases]\n",
        "\n",
        "normal_labels = np.zeros(len(normal_data)) # labell '0' for normal cases\n",
        "positive_labels = np.ones(len(positive_cases)) # label '1' for positive cases\n",
        "\n",
        "#now the data contains 8537 positive cases and 3840 normal cases along with their labels\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tX9q0I_ZLTrY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets shuffle the data and labels:\n",
        "new_labels = np.concatenate((normal_labels, positive_labels))\n",
        "from random import shuffle\n",
        "shuffle(new_labels)\n",
        "\n",
        "new_data = np.concatenate((Data[0], Data[1]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Final Data and Labels:\n",
        "Y = new_labels\n",
        "X = new_data.reshape(12377, 128, 128, 1)\n",
        "shuffle(X)\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReJHOIYbZRaS",
        "outputId": "dba70dc0-427e-42ad-8b52-4300ec64c6a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12377, 128, 128, 1)\n",
            "(12377,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y[0:13]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoBcgu8y4byP",
        "outputId": "4442cd2d-b7f8-4907-ca09-844f33bdce62"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nRows,nCols, nDims = X.shape[1:]\n",
        "input_shape = (nRows, nCols, nDims)\n",
        "print(input_shape)\n",
        "\n",
        "Y_new = np_utils.to_categorical(Y)\n",
        "print(Y_new.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS3RUuyzOHr6",
        "outputId": "e7fc0bf9-a288-4cbb-9458-fe5aa43de2ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 128, 1)\n",
            "(12377, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_new[0:13]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXgPD8H9cydN",
        "outputId": "b8cb6994-3d59-4c45-c38a-0ff9c5c34b81"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the dataset into training and test sets:\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_new, test_size = 0.20, random_state=42)\n",
        "\n",
        "print(len(new_data))\n",
        "print(len(X_train))\n",
        "print(Y_train.shape)\n",
        "print(len(X_test))\n",
        "print(Y_test.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpCDTX4ixmd-",
        "outputId": "593a03df-4791-4f08-fc62-c7e532269169"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12377\n",
            "9901\n",
            "(9901, 2)\n",
            "2476\n",
            "(2476, 2)\n",
            "(2476, 128, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Building architecture for Image Classification:\n",
        "\n",
        "#Input layer in Architecture:\n",
        "\n",
        "def Model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(16, (7, 7), padding = 'same', activation = 'relu',kernel_initializer = 'he_normal', input_shape = input_shape))\n",
        "  model.add(Conv2D(16, (7,7), activation = 'relu',kernel_initializer = 'he_normal', padding = 'same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "  \n",
        "\n",
        "  model.add(Conv2D(32, (7, 7), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
        "  model.add(Conv2D(32, (7,7), activation = 'relu', padding = 'same', kernel_initializer='he_normal'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "  \n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
        "  model.add(Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer='he_normal'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "  \n",
        "\n",
        "  model.add(Conv2D(128, (9, 9), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
        "  model.add(Conv2D(128, (9, 9), activation = 'relu', padding = 'same', kernel_initializer='he_normal'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "  \n",
        "\n",
        "  model.add(Conv2D(256, (1, 1), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
        "  model.add(Conv2D(256, (1, 1), activation = 'relu', padding = 'same', kernel_initializer='he_normal'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "  \n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
        "  model.add(Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer='he_normal'))\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation = 'relu'))\n",
        "  model.add(Dense(2, activation = 'sigmoid'))\n",
        "\n",
        "  return model  "
      ],
      "metadata": {
        "id": "xwsLS4GPOj5f"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "model = Model()\n",
        "batch = 256\n",
        "epochs = 25"
      ],
      "metadata": {
        "id": "AGVNBEUj02M6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate  = 0.0000001)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "N5uRefW0ezOc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Model fitting:\n",
        "# #Modelcheckpoint:\n",
        "# Checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_HRCT.h5', verbose = 1, save_best_only=True)\n",
        "# reduce  = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 2, min_lr = 0.000000001, verbose = 1)\n",
        "\n",
        "# logdir = 'HRCT'\n",
        "\n",
        "# tensorboard_Vis = tf.keras.callbacks.TensorBoard(log_dir = logdir)\n",
        "\n",
        "history = model.fit(X_train, Y_train, validation_split = 0.25, batch_size = 256, epochs = 20)#, callbacks = [Checkpointer, reduce, tensorboard_Vis])"
      ],
      "metadata": {
        "id": "0trrs3QConjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96abaf9-db39-4e80-fb78-69533748fb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            " 7/30 [======>.......................] - ETA: 25:41 - loss: 0.9066 - accuracy: 0.4308"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "id": "8eBFmYjyfrC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, Y_test, verbose = 1)"
      ],
      "metadata": {
        "id": "IWEjTEa-6-fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test)\n",
        "y_classes = [np.argmax(element) for element in pred]\n",
        "print('Predicted labels:',y_classes[0:20])\n",
        "print('Actual labels:',Y_test[0:20])"
      ],
      "metadata": {
        "id": "DC5GOtJlg72B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "keras.utils.plot_model(model, to_file = 'model_HRCT.png', show_layer_names = True)"
      ],
      "metadata": {
        "id": "MCupFSxYMM01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test,  Y_test, verbose=2)"
      ],
      "metadata": {
        "id": "007XsgT0sB0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = 'HRCT'\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir HRCT/"
      ],
      "metadata": {
        "id": "ZsVrzgf8Nsqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = model.predict(X_test)\n",
        "predictions = np.argmax(A, axis = 1)\n",
        "print(\"Actual Label of Image\", Y_test[10:20])\n",
        "print(\"Predicted Label of Image\", predictions[10:20])"
      ],
      "metadata": {
        "id": "e9W_NdxOsDMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WbhbzvT8NMXY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}